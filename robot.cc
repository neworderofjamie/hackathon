// BoB robotics includes
#include "common/macros.h"
#include "common/main.h"
#include "common/logging.h"
#include "common/stopwatch.h"
#include "gazebo/node.h"
#include "robots/mecanum.h"
#include "video/rpi_cam.h"

// SpineML simulator includes
#include "spineml/simulator/simulator.h"

// Third-party includes
#include "third_party/units.h"

// Standard C++ includes
#include <chrono>
#include <iostream>
#include <thread>
#include <cstring>

using namespace BoBRobotics;
using namespace std::literals;
using namespace units::literals;
using namespace BoBRobotics::Video;

int bob_main(int, char **)
{
    // Camera resolution - matches robot camera
    const cv::Size cameraResolution(152, 72);

    // How much bigger to show camera image on screen
    const int displayScale = 4;

    // How much SMALLER to make image that goes into network
    const int inputScale = 4;

    // Calculate number of pixels each channel will communicate
    const int numInputPixels = (cameraResolution.width / inputScale) * (cameraResolution.height / inputScale);

    RPiCamera cam(50106);

    Robots::Mecanum robot("/dev/ttyUSB0");
    HID::Joystick joystick(0.25f);

    // Create window to show camera image
    cv::namedWindow("Camera", cv::WINDOW_NORMAL);
    cv::resizeWindow("Camera", cameraResolution.width * displayScale,
                     cameraResolution.height * displayScale);


    // Create SpineML simulator object
    SpineMLSimulator::Simulator simulator("experiment0.xml", ".");

    // Get external loggers used for accessing steering signals generated by network
    const auto *steerLeft = simulator.getExternalLogger("steer_left");
    const auto *steerRight = simulator.getExternalLogger("steer_right");
    const auto *driveForward = simulator.getExternalLogger("drive_forward");
    if(steerLeft) {
        BOB_ASSERT(steerLeft->getModelPropertySize() == 1);
        std::cout << "Steer left output found!" << std::endl;
    }
    if(steerRight) {
        BOB_ASSERT(steerRight->getModelPropertySize() == 1);
        std::cout << "Steer right output found!" << std::endl;
    }
    if(driveForward) {
        BOB_ASSERT(driveForward->getModelPropertySize() == 1);
        std::cout << "Drive forward output found!" << std::endl;
    }

    // Get external inputs used for providing sensor input to the network
    auto *cameraRed = simulator.getExternalInput("camera_red");
    auto *cameraGreen = simulator.getExternalInput("camera_green");
    auto *cameraBlue = simulator.getExternalInput("camera_blue");
    if(cameraRed) {
        BOB_ASSERT(std::distance(cameraRed->getBufferBegin(), cameraRed->getBufferEnd()) == numInputPixels);
        std::cout << "Camera red input found!" << std::endl;
    }
    if(cameraGreen) {
        BOB_ASSERT(std::distance(cameraGreen->getBufferBegin(), cameraGreen->getBufferEnd()) == numInputPixels);
        std::cout << "Camera green input found!" << std::endl;
    }
    if(cameraBlue) {
        BOB_ASSERT(std::distance(cameraBlue->getBufferBegin(), cameraBlue->getBufferEnd()) == numInputPixels);
        std::cout << "Camera blue input found!" << std::endl;
    }

    cv::Mat frameCamera;
    cv::Mat frameUnwrapped;
    cv::Mat frameUnwrappedChannels[3];
    cv::Mat frameUnwrappedChannelsDownsampled[3];


    Stopwatch timer;
    timer.start();

    do
    {
        // Poll joystick
        joystick.update();

        // Read frame
        cam.readFrame(frameCamera);

        // **HACK** horizontally flip camera image
        cv::flip(frameCamera, frameUnwrapped, 1);

        // Split channels
        cv::split(frameUnwrapped, frameUnwrappedChannels);

        // Downsample each channel
        for(unsigned int c = 0; c < 3; c++) {
            cv::resize(frameUnwrappedChannels[c], frameUnwrappedChannelsDownsampled[c],
                    cv::Size(cameraResolution.width / inputScale, cameraResolution.height / inputScale));
        }

        // Show unwrapped frame
        cv::imshow("Camera", frameUnwrapped);


        // If camera inputs are found, transform pixels to double and inject
        if(cameraRed) {
            std::transform(frameUnwrappedChannelsDownsampled[0].begin<uint8_t>(), frameUnwrappedChannelsDownsampled[0].end<uint8_t>(),
                           cameraRed->getBufferBegin(), [](uint8_t pixel){ return (double)pixel / 255.0; });
        }
        if(cameraGreen) {
            std::transform(frameUnwrappedChannelsDownsampled[1].begin<uint8_t>(), frameUnwrappedChannelsDownsampled[1].end<uint8_t>(),
                           cameraGreen->getBufferBegin(), [](uint8_t pixel){ return (double)pixel / 255.0; });
        }
        if(cameraBlue) {
            std::transform(frameUnwrappedChannelsDownsampled[2].begin<uint8_t>(), frameUnwrappedChannelsDownsampled[2].end<uint8_t>(),
                           cameraBlue->getBufferBegin(), [](uint8_t pixel){ return (double)pixel / 255.0; });
        }

        // Advance SpineML simulation
        simulator.stepTime();

        // If A is held down, drive robot with joystick
        if(timer.elapsed() > std::chrono::milliseconds(20)) {
            timer.start();

            if(joystick.isDown(HID::JButton::A)) {
                robot.drive(joystick);
            }
            // Otherwise, if the outputs are present
            else if(steerLeft && steerRight && driveForward) {
                // Read steering signals
                const float left = *steerLeft->getStateVarBegin();
                const float right = *steerRight->getStateVarBegin();
                const float forward = *driveForward->getStateVarBegin();

                std::cout << left << "," << right << "," << forward << std::endl;
                // Drive robot
                robot.omni2D(0.0f, -forward * 0.5f, (right - left) * 0.5f);
            }
        }

        // Pump OpenCV events
        cv::waitKey(1);
    } while (!joystick.isPressed(HID::JButton::B));

    std::cout << "Stopping" << std::endl;
    robot.stopMoving();

    return EXIT_SUCCESS;
}
